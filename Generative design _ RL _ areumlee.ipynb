{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "import time\n",
    "# import subprocess\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = 4\n",
    "position = 3\n",
    "g_coord = np.array([0.0,0,3,0,6,0,9,0,9,3,9,6,9,9,12,9,15,9,18,9])\n",
    "dx = 0.1\n",
    "change_nodes = list(range(1,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  3.  0.  6.  0.  9.  0.  9.  3.  9.  6.  9.  9. 12.  9. 15.  9.\n",
      " 18.  9.]\n"
     ]
    }
   ],
   "source": [
    "print (g_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.   0.   3.   0.   6.   0.   9.   0.   9.1  3.   9.   6.   9.   9.\n",
      " 12.   9.  15.   9.  18.   9. ]\n"
     ]
    }
   ],
   "source": [
    "g_coord[int(2*change_nodes[position])]+=dx\n",
    "\n",
    "print(g_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.   0.   3.   0.   6.   0.   9.   0.   9.1  3.1  9.   6.   9.   9.\n",
      " 12.   9.  15.   9.  18.   9. ]\n"
     ]
    }
   ],
   "source": [
    "g_coord[int(2*change_nodes[position])+1]+=dx\n",
    "\n",
    "print (g_coord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# action 0~4 ------action = tf.multinomial(tf.log(outputs), num_samples=1,output_dtype=tf.int32)\n",
    "# ----------------- estimated probabilities 기반의 0~4 값의 랜덤 action 선택\n",
    "# position -------------- pst=random.randint(0,7) ----------------0~7 사이의 랜덤 값 1개  \n",
    "# g_coord \n",
    "# dx    ----------------- dx=0.1 --------------------------------- 0.1로 통일\n",
    "# change_nodes  -------- list(range(1,9))개 ---------------------- [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "\n",
    "# 현재 / 다음 state에 0.1 곱함 = 9.1  3.1  \n",
    "\n",
    "\n",
    "def alter_coord(action, position, g_coord, dx=0.1, change_nodes=list(range(1,9))):\n",
    "        \n",
    "    if action==0:\n",
    "        g_coord[int(2*change_nodes[position])]+=dx\n",
    "        g_coord[int(2*change_nodes[position])+1]+=dx\n",
    "    elif action==1:\n",
    "        g_coord[int(2*change_nodes[position])]+=dx\n",
    "        g_coord[int(2*change_nodes[position])+1]-=dx\n",
    "    if action==2:\n",
    "        g_coord[int(2*change_nodes[position])]-=dx\n",
    "        g_coord[int(2*change_nodes[position])+1]+=dx\n",
    "    elif action==3:\n",
    "        g_coord[int(2*change_nodes[position])]-=dx\n",
    "        g_coord[int(2*change_nodes[position])+1]-=dx    \n",
    "    elif action==4:\n",
    "        g_coord[int(2*change_nodes[position])+1]-=0\n",
    "             \n",
    "    return g_coorddnj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def observe(position, coord, displ):    \n",
    "    return position, coord[0], coord[1],coord[2], coord[3], coord[4], coord[5],coord[6], \\\n",
    "coord[7], coord[8], coord[9],coord[10], coord[11], coord[12], coord[13],coord[14], coord[15],\\\n",
    "coord[16], coord[17],coord[18], coord[19], np.max(abs(displ))\n",
    "\n",
    "\n",
    "#np.sum(abs(displ))\n",
    "\n",
    "#displ[2]\n",
    "\n",
    "# displ[0],displ[1],displ[2],displ[3],displ[4],\\\n",
    "# displ[5],displ[6],displ[7],displ[8],displ[9],displ[10],displ[11],displ[12],displ[13],\\\n",
    "# displ[14],displ[15],displ[16],displ[17],displ[18],displ[19],displ[20],displ[21],\\\n",
    "# displ[22],displ[23],displ[24],displ[25],displ[26],displ[27],displ[28],displ[29]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finite Element Model of the Plane Truss structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlaneFrameElementLength(x1,y1,x2,y2):\n",
    "    return math.sqrt((x2-x1)*(x2-x1) + (y2-y1)*(y2-y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlaneFrameElementStiffness(E,A,I,L,theta):\n",
    "    pi=3.14159265   \n",
    "    x = theta*pi/180\n",
    "    C = math.cos(x)\n",
    "    S = math.sin(x)\n",
    "    w1 = A*C*C + 12*I*S*S/(L*L)\n",
    "    w2 = A*S*S + 12*I*C*C/(L*L)\n",
    "    w3 = (A-12*I/(L*L))*C*S\n",
    "    w4 = 6*I*S/L\n",
    "    w5 = 6*I*C/L\n",
    "    \n",
    "    return E/L*np.array([[w1, w3, -w4, -w1, -w3, -w4],[ w3, w2, w5, -w3, -w2, w5],\n",
    "                        [-w4, w5, 4*I, w4, -w5, 2*I],[ -w1, -w3, w4, w1, w3, w4],\n",
    "                        [-w3, -w2, -w5, w3, w2, -w5], [-w4, w5, 2*I, w4, -w5, 4*I]])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlaneFrameAssemble(K,k,i,j):\n",
    "    K[3*i,3*i] = K[3*i,3*i] + k[0,0]\n",
    "    K[3*i,3*i+1] = K[3*i,3*i+1] + k[0,1]    \n",
    "    K[3*i,3*i+2] = K[3*i,3*i+2] + k[0,2]\n",
    "    K[3*i,3*j] = K[3*i,3*j] + k[0,3]\n",
    "    K[3*i,3*j+1] = K[3*i,3*j+1] + k[0,4]\n",
    "    K[3*i,3*j+2] = K[3*i,3*j+2] + k[0,5]\n",
    "    K[3*i+1,3*i] = K[3*i+1,3*i] + k[1,0]\n",
    "    K[3*i+1,3*i+1] = K[3*i+1,3*i+1] + k[1,1]\n",
    "    K[3*i+1,3*i+2] = K[3*i+1,3*i+2] + k[1,2]\n",
    "    K[3*i+1,3*j] = K[3*i+1,3*j] + k[1,3]\n",
    "    K[3*i+1,3*j+1] = K[3*i+1,3*j+1] + k[1,4]\n",
    "    K[3*i+1,3*j+2] = K[3*i+1,3*j+2] + k[1,5]\n",
    "    K[3*i+2,3*i] = K[3*i+2,3*i] + k[2,0]\n",
    "    K[3*i+2,3*i+1] = K[3*i+2,3*i+1] + k[2,1]\n",
    "    K[3*i+2,3*i+2] = K[3*i+2,3*i+2] + k[2,2]\n",
    "    K[3*i+2,3*j] = K[3*i+2,3*j] + k[2,3]\n",
    "    K[3*i+2,3*j+1] = K[3*i,3*j+1] + k[2,4]\n",
    "    K[3*i+2,3*j+2] = K[3*i+2,3*j+2] + k[2,5]\n",
    "    K[3*j,3*i] = K[3*j,3*i] + k[3,0]\n",
    "    K[3*j,3*i+1] = K[3*j,3*i+1] + k[3,1]\n",
    "    K[3*j,3*i+2] = K[3*j,3*i+2] + k[3,2]\n",
    "    K[3*j,3*j] = K[3*j,3*j] + k[3,3]\n",
    "    K[3*j,3*j+1] = K[3*j,3*j+1] + k[3,4]\n",
    "    K[3*j,3*j+2] = K[3*j,3*j+2] + k[3,5]   \n",
    "    K[3*j+1,3*i] = K[3*j+1,3*i] + k[4,0]\n",
    "    K[3*j+1,3*i+1] = K[3*j+1,3*i+1] + k[4,1]\n",
    "    K[3*j+1,3*i+2] = K[3*j+1,3*i+2] + k[4,2]\n",
    "    K[3*j+1,3*j] = K[3*j+1,3*j] + k[4,3]\n",
    "    K[3*j+1,3*j+1] = K[3*j+1,3*j+1] + k[4,4]\n",
    "    K[3*j+1,3*j+2] = K[3*j+1,3*j+2] + k[4,5]\n",
    "    K[3*j+2,3*i] = K[3*j+2,3*i] + k[5,0]\n",
    "    K[3*j+2,3*i+1] = K[3*j+2,3*i+1] + k[5,1]\n",
    "    K[3*j+2,3*i+2] = K[3*j+2,3*i+2] + k[5,2]\n",
    "    K[3*j+2,3*j] = K[3*j+2,3*j] + k[5,3]\n",
    "    K[3*j+2,3*j+1] = K[3*j+2,3*j+1] + k[5,4]\n",
    "    K[3*j+2,3*j+2] = K[3*j+2,3*j+2] + k[5,5]\n",
    "    \n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FEA_u(coord, elcon, bc_u_elim, f_after_u_elim, I=5e-5, A=1e-4, E=210e6):\n",
    "    K=np.zeros(shape=(3*np.max(elcon)+3,3*np.max(elcon)+3))\n",
    "    pi=3.14159265\n",
    "    for el in elcon:\n",
    "        L=PlaneFrameElementLength(coord[el[0]][0],coord[el[0]][1],coord[el[1]][0],coord[el[1]][1])\n",
    "        theta=math.atan((coord[el[1]][1]-coord[el[0]][1])/(coord[el[1]][0]-coord[el[0]][0]+1e-13))*180/pi\n",
    "        k=PlaneFrameElementStiffness(E,A,I,L,theta)\n",
    "        K=PlaneFrameAssemble(K,k,el[0],el[1])\n",
    "    K=np.delete(K,bc_u_elim,0)\n",
    "    K=np.delete(K,bc_u_elim,1)\n",
    "    \n",
    "\n",
    "    d=np.dot(np.linalg.inv(K),f_after_u_elim)\n",
    "    ans=np.zeros(shape=(3*len(coord)))\n",
    "\n",
    "    j=0\n",
    "    for i in range(len(ans)):\n",
    "        if i not in bc_u_elim:\n",
    "            ans[i]=d[j]\n",
    "            j+=1\n",
    "            if j>len(d)-1:\n",
    "                break\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Policy - Policy Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Details of model can be found in the book:\n",
    "# Hands-On Machine Learning with Scikit-Learn & TensorFlow. Aurйlien Gйron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the NN architecture must be tailored to different FE models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 22 \n",
    "n_hidden = 70 \n",
    "n_outputs = 5 \n",
    "initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Build the neural network\n",
    "X_ = tf.placeholder(tf.float64, shape=[None, n_inputs], name=\"X_\")\n",
    "hidden = fully_connected(X_, n_hidden, activation_fn=tf.nn.elu, weights_initializer=initializer)\n",
    "hidden1 = fully_connected(hidden, n_hidden, activation_fn=tf.nn.elu, weights_initializer=initializer)\n",
    "logits = fully_connected(hidden1, n_outputs, activation_fn=None, weights_initializer=initializer)\n",
    "outputs = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "# Select a random action based on the estimated probabilities\n",
    "action = tf.multinomial(tf.log(outputs), num_samples=1,output_dtype=tf.int32)\n",
    "\n",
    "y=tf.reshape(tf.one_hot(action,depth=5,dtype=tf.float64),[5,1])\n",
    "xentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=tf.transpose(logits))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "grads_and_vars = optimizer.compute_gradients(xentropy)\n",
    "gradients = [grad for grad, variable in grads_and_vars]\n",
    "gradient_placeholders = []\n",
    "grads_and_vars_feed = []\n",
    "for grad, variable in grads_and_vars:\n",
    "    gradient_placeholder = tf.placeholder(tf.float64, shape=grad.get_shape())\n",
    "    gradient_placeholders.append(gradient_placeholder)\n",
    "    grads_and_vars_feed.append((gradient_placeholder, variable))\n",
    "\n",
    "training_op = optimizer.apply_gradients(grads_and_vars_feed)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_rewards(rewards, discount_rate=0.97):\n",
    "    discounted_rewards = np.empty(len(rewards))\n",
    "    cumulative_rewards = 0\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        cumulative_rewards = rewards[step] + cumulative_rewards * discount_rate\n",
    "        discounted_rewards[step] = cumulative_rewards\n",
    "    return discounted_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_and_normalize_rewards(all_rewards, discount_rate=0.97):\n",
    "    all_discounted_rewards = [discount_rewards(rewards) for rewards in all_rewards]\n",
    "    flat_rewards = np.concatenate(all_discounted_rewards)\n",
    "    reward_mean = flat_rewards.mean()\n",
    "    reward_std = flat_rewards.std()\n",
    "    return [(discounted_rewards - reward_mean)/reward_std for discounted_rewards in all_discounted_rewards]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function must be tailored to different FE models\n",
    "\n",
    "def reward_(obs_,obs): \n",
    "#     if np.max(abs(np.array(obs_[22:-1])))>np.max(abs(np.array(obs[22:-1]))): \n",
    "#     if sum(abs(np.array(obs_[22:-1])))>sum(abs(np.array(obs[22:-1]))):\n",
    "#     return sum(abs(np.array(obs_[22:-1]))>abs(np.array(obs[22:-1]))) \n",
    "\n",
    "#     if abs(obs_[-1])>abs(obs[-1]):\n",
    "    if obs_[-1]>obs[-1]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the training code must be tailored to different FE models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for 0 epoch 21.1832115650177 sec\n",
      "\n",
      "Time taken for 5 epoch 133.3656280040741 sec\n",
      "\n",
      "Time taken for 10 epoch 236.10750460624695 sec\n",
      "\n",
      "Time taken for 15 epoch 339.79643535614014 sec\n",
      "\n",
      "Time taken for 20 epoch 447.7276086807251 sec\n",
      "\n",
      "Time taken for 25 epoch 551.0045156478882 sec\n",
      "\n",
      "Time taken for 30 epoch 654.4574329853058 sec\n",
      "\n",
      "Time taken for 35 epoch 757.5803310871124 sec\n",
      "\n",
      "Time taken for 40 epoch 864.4974465370178 sec\n",
      "\n",
      "Time taken for 45 epoch 967.4403345584869 sec\n",
      "\n",
      "Time taken for 50 epoch 1071.0282592773438 sec\n",
      "\n",
      "Time taken for 55 epoch 1174.5751819610596 sec\n",
      "\n",
      "Time taken for 60 epoch 1281.2382826805115 sec\n",
      "\n",
      "Time taken for 65 epoch 1389.071450471878 sec\n",
      "\n",
      "Time taken for 70 epoch 1491.3473002910614 sec\n",
      "\n",
      "Time taken for 75 epoch 1594.0811762809753 sec\n",
      "\n",
      "Time taken for 80 epoch 1701.1553003787994 sec\n",
      "\n",
      "Time taken for 85 epoch 1804.2781989574432 sec\n",
      "\n",
      "Time taken for 90 epoch 1907.2430880069733 sec\n",
      "\n",
      "Time taken for 95 epoch 2010.9220180511475 sec\n",
      "\n",
      "Time taken for 100 epoch 2114.987970352173 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_iterations =101 #251  # number of training iterations\n",
    "n_max_steps = 500 #1000  # max steps per episode\n",
    "n_games_per_update = 10 # train the policy every 10 episodes\n",
    "save_iterations = 5 # save the model every 10 training iterations\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    start=time.time()\n",
    "    init.run() \n",
    "    \n",
    "#     saver.restore(sess, tf.train.latest_checkpoint(\"./policy4/\"))    \n",
    "#     tf.get_default_graph()\n",
    "    \n",
    "    for iteration in range(n_iterations):\n",
    "               \n",
    "        all_rewards = [] # all sequences of raw rewards for each episode\n",
    "        all_gradients = [] # gradients saved at each step of each episode\n",
    "             \n",
    "        for game in range(n_games_per_update):\n",
    "            current_rewards = [] # all raw rewards from the current episode\n",
    "            current_gradients = [] # all gradients from the current episode\n",
    "            \n",
    "            pst=random.randint(0,7)\n",
    "            g_coord = alter_coord(4, pst, np.array([0.0,0,3,0,6,0,9,0,9,3,9,6,9,9,12,9,15,9,18,9]),\n",
    "                                          dx=0.1, change_nodes=list(range(1,9)))\n",
    "            \n",
    "            \n",
    "            displ = FEA_u(g_coord.reshape(10,2), elcon=np.array([[0,1],[1,2],[2,3],[3,4],[4,5],[5,6],[6,7],[7,8],[8,9]]),\n",
    "                                                    bc_u_elim=[0,1,2],\n",
    "                                                    f_after_u_elim=np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-10,0,0]), \n",
    "                                                    I=5e-5, A=2e-2, E=210e6)\n",
    "            \n",
    "            obs=observe(pst, g_coord,displ)\n",
    "            \n",
    "            \n",
    "            for step in range(n_max_steps):\n",
    "                action_val, gradients_val = sess.run([action, gradients],\n",
    "                                                     feed_dict={X_: np.array(obs).reshape(1,n_inputs)}) \n",
    "                obs_=obs        \n",
    "                g_coord = alter_coord(action_val[0][0], pst, g_coord,\n",
    "                                          dx=0.1, change_nodes=list(range(1,9)))\n",
    "                \n",
    "                pst=random.randint(0,7)\n",
    "                \n",
    "                if PlaneFrameElementLength(g_coord[0],g_coord[1],g_coord[2],g_coord[3])<0.02:\n",
    "                    break\n",
    "            \n",
    "                if PlaneFrameElementLength(g_coord[2],g_coord[3],g_coord[4],g_coord[5])<0.02:\n",
    "                    break\n",
    "             \n",
    "                if PlaneFrameElementLength(g_coord[4],g_coord[5],g_coord[6],g_coord[7])<0.02:\n",
    "                    break\n",
    "            \n",
    "                if PlaneFrameElementLength(g_coord[6],g_coord[7],g_coord[8],g_coord[9])<0.02:\n",
    "                    break\n",
    "            \n",
    "                if PlaneFrameElementLength(g_coord[8],g_coord[9],g_coord[10],g_coord[11])<0.02:\n",
    "                    break\n",
    "            \n",
    "             \n",
    "                if PlaneFrameElementLength(g_coord[10],g_coord[11],g_coord[12],g_coord[13])<0.02:\n",
    "                    break\n",
    "            \n",
    "                if PlaneFrameElementLength(g_coord[12],g_coord[13],g_coord[14],g_coord[15])<0.02:\n",
    "                    break\n",
    "            \n",
    "                if PlaneFrameElementLength(g_coord[14],g_coord[15],g_coord[16],g_coord[17])<0.02:\n",
    "                    break\n",
    "            \n",
    "                if PlaneFrameElementLength(g_coord[16],g_coord[17],g_coord[18],g_coord[19])<0.02:\n",
    "                    break\n",
    "                            \n",
    "                \n",
    "                displ = FEA_u(g_coord.reshape(10,2), elcon=np.array([[0,1],[1,2],[2,3],[3,4],[4,5],[5,6],[6,7],[7,8],[8,9]]),\n",
    "                                                    bc_u_elim=[0,1,2],\n",
    "                                                    f_after_u_elim=np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-10,0,0]), \n",
    "                                                    I=5e-5, A=2e-2, E=210e6)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                obs=observe(pst,g_coord,displ) \n",
    "                \n",
    "                reward=reward_(obs_,obs)\n",
    "                \n",
    "                current_rewards.append(reward)\n",
    "                current_gradients.append(gradients_val)\n",
    "\n",
    "            all_rewards.append(current_rewards)\n",
    "            all_gradients.append(current_gradients)\n",
    "\n",
    "    \n",
    "            \n",
    "        # At this point we have run the policy for 10 episodes, and we are\n",
    "        # ready for a policy update using the algorithm described earlier.\n",
    "        all_rewards = discount_and_normalize_rewards(all_rewards)\n",
    "        \n",
    "        \n",
    "        \n",
    "        feed_dict = {}\n",
    "        for var_index, grad_placeholder in enumerate(gradient_placeholders):\n",
    "            # multiply the gradients by the action scores, and compute the mean\n",
    "            mean_gradients = np.mean([reward * all_gradients[game_index][step][var_index] \n",
    "                                      for game_index, rewards in enumerate(all_rewards)\n",
    "                                      for step, reward in enumerate(rewards)],axis=0)\n",
    "            feed_dict[grad_placeholder] = mean_gradients\n",
    "        \n",
    "        \n",
    "        sess.run(training_op, feed_dict=feed_dict)\n",
    "        \n",
    "        if iteration % save_iterations == 0:\n",
    "#             print(\"Saving {} iteration\".format(iteration))\n",
    "            print('Time taken for {} epoch {} sec\\n'.format(iteration, time.time() - start))\n",
    "            saver.save(sess, \"./policy4/pinjointed4.ckpt\")\n",
    "\n",
    "# end=time.time()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI designing the spool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(coord):\n",
    "    with tf.Session() as sess:\n",
    "        saver = tf.train.import_meta_graph('./policy4/pinjointed4.ckpt.meta')\n",
    "        saver.restore(sess, \"./policy4/pinjointed4.ckpt\") \n",
    "\n",
    "        graph = tf.get_default_graph()\n",
    "        outputs = graph.get_tensor_by_name(\"Y_proba:0\") \n",
    "        X_ = graph.get_tensor_by_name(\"X_:0\") \n",
    "                \n",
    "#         pst=random.randint(0,7)\n",
    "        \n",
    "        j=0\n",
    "        pst=j%8\n",
    "        g_coord = alter_coord(4, pst, coord, dx=0.1, change_nodes=list(range(1,9)))\n",
    "            \n",
    "        displ = FEA_u(g_coord.reshape(10,2), elcon=np.array([[0,1],[1,2],[2,3],[3,4],[4,5],[5,6],[6,7],[7,8],[8,9]]),\n",
    "                                                    bc_u_elim=[0,1,2],\n",
    "                                                    f_after_u_elim=np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-10,0,0]), \n",
    "if PlaneFrameElementLength(g_coord[8],g_coord[9],g_coord[10],g_coord[11])<0.02:\n",
    "                break\n",
    "                \n",
    "            if PlaneFrameElementLength(g_coord[10],g_coord[11],g_coord[12],g_coord[13])<0.02:\n",
    "                break\n",
    "            \n",
    "            if PlaneFrameElementLength(g_coord[12],g_coord[13],g_coord[14],g_coord[15])<0.02:\n",
    "                break\n",
    "            \n",
    "            if PlaneFrameElementLength(g_coord[14],g_coord[15],g_coord[16],g_coord[17])<0.02:\n",
    "                break\n",
    "            \n",
    "            if PlaneFrameElementLength(g_coord[16],g_coord[17],g_coord[18],g_coord[19])<0.02if PlaneFrameElementLength(g_coord[16],g_coord[17],g_coord[18],g_coord[19])<0.02값if PlaneFrameElementLength(g_coord[16],g_coord[17],g_coord[18],g_coord[19])<0.02if PlaneFrameElementLength(g_coord[16],g_coord[17],g_coord[18],g_coord[19])<0.02값:\n",
    "                break\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "            displ = FEA_u(g_coord.reshape(10,2), elcon=np.array([[0,1],[1,2],[2,3],[3,4],[4,5],[5,6],[6,7],[7,8],[8,9]]),\n",
    "                                                    bc_u_elim=[0,1,2],\n",
    "                                                    f_after_u_elim=np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-10,0,0]), \n",
    "                                                    I=5e-5, A=2e-2, E=210e6)\n",
    "            \n",
    "            obs=observe(pst, g_coord, displ)\n",
    "        print(\"after: \", np.max(abs(displ)))\n",
    "#         print(\"after: \", abs(displ[2]))\n",
    "        return obs,g_coord        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./policy4/pinjointed4.ckpt\n",
      "before:  1.3885714292728224\n",
      "after:  0.18071429767546054\n"
     ]
    }
   ],
   "source": [
    "obs, g_coord = predict(np.array([0.0,0,3,0,6,0,9,0,9,3,9,6,9,9,12,9,15,9,18,9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0. ,  0. ,  2.3,  0.7,  5.3,  0.7,  8.4,  0.6,  8.4,  3.6,  8.4,\n",
       "        6.6,  8.4,  9.6, 11.4,  9.6, 14.4,  9.6, 18. ,  9. ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(coord,color,elcon):\n",
    "    coord=coord.reshape(np.max(elcon)+1,2)\n",
    "    plt.figure(figsize=(13,5))\n",
    "    for item in elcon:\n",
    "        plt.plot([coord[item[0]][0],coord[item[1]][0]],[coord[item[0]][1],coord[item[1]][1]],color=color)\n",
    "       \n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Design "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw(np.array([0,0,3,0,6,0,9,0,9,3,9,6,9,9,12,9,15,9,18,9]),color=\"green\",elcon=np.array([[0,1],[1,2],[2,3],[3,4],[4,5],[5,6],[6,7],[7,8],[8,9]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design by AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw(g_coord,color=\"blue\",elcon=np.array([[0,1],[1,2],[2,3],[3,4],[4,5],[5,6],[6,7],[7,8],[8,9]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
